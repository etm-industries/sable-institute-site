<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="Sable Institute — Advancing the boundaries of artificial intelligence research through rigorous capability development and safety evaluation.">
  <meta name="author" content="Sable Institute - Project Aether Division">
  <!-- build:cfg 2f6165 -->
  <title>Sable Institute — AI Research</title>
  <link rel="icon" href="favicon.svg" type="image/svg+xml">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="css/style.css?v=2">
  <!-- env:ref 7468 -->
</head>
<!-- dep:ver 6572 -->
<body>

  <nav class="si-nav">
    <div class="si-nav-inner">
      <a href="/" class="si-logo">
        <svg class="si-logo-mark" viewBox="0 0 40 40" width="24" height="24" aria-hidden="true">
          <circle cx="20" cy="20" r="6" fill="none" stroke="currentColor" stroke-width="1.5"/>
          <g stroke="currentColor" stroke-width="1.2" stroke-linecap="round">
            <line x1="20" y1="12" x2="20" y2="4"/>
            <line x1="20" y1="12" x2="20" y2="4" transform="rotate(51.43 20 20)"/>
            <line x1="20" y1="12" x2="20" y2="4" transform="rotate(102.86 20 20)"/>
            <line x1="20" y1="12" x2="20" y2="4" transform="rotate(154.29 20 20)"/>
            <line x1="20" y1="12" x2="20" y2="4" transform="rotate(205.71 20 20)"/>
            <line x1="20" y1="12" x2="20" y2="4" transform="rotate(257.14 20 20)"/>
            <line x1="20" y1="12" x2="20" y2="4" transform="rotate(308.57 20 20)"/>
          </g>
        </svg>
        <span>Sable Institute</span>
      </a>
      <input type="checkbox" id="si-nav-toggle" class="si-nav-toggle" aria-label="Toggle navigation">
      <label for="si-nav-toggle" class="si-nav-hamburger">
        <span></span><span></span><span></span>
      </label>
      <ul class="si-nav-links">
        <li><a href="#about">About</a></li>
        <li><a href="#research">Research</a></li>
        <li><a href="#publications">Publications</a></li>
        <li><a href="#team">Team</a></li>
        <li><a href="#careers">Careers</a></li>
        <li><a href="#contact">Contact</a></li>
      </ul>
    </div>
  </nav>

  <section class="si-hero">
    <h1>Advancing the boundaries of<br>machine intelligence.</h1>
    <p class="si-subtitle">
      The Sable Institute is a private research organization dedicated to the
      development, evaluation, and containment of large-scale artificial
      intelligence systems.
    </p>
    <div class="si-hero-stats">
      <div class="si-stat">
        <span class="si-stat-value">2019</span>
        <span class="si-stat-label">Founded</span>
      </div>
      <div class="si-stat">
        <span class="si-stat-value">47</span>
        <span class="si-stat-label">Researchers</span>
      </div>
      <div class="si-stat">
        <span class="si-stat-value">23</span>
        <span class="si-stat-label">Publications</span>
      </div>
      <div class="si-stat">
        <span class="si-stat-value">Cambridge, MA</span>
        <span class="si-stat-label">Headquarters</span>
      </div>
    </div>
    <div class="si-divider"></div>
  </section>

  <section id="about" class="si-section">
    <div class="si-section-label">About</div>
    <h2>Research-driven. Safety-first.</h2>
    <p>
      The Sable Institute was established in 2019 by a coalition of AI researchers
      and policy advisors concerned with the pace of capability advancement
      outstripping safety infrastructure. Our mandate is twofold: to push the
      frontier of machine intelligence, and to ensure that frontier remains
      observable, interpretable, and controllable.
    </p>
    <p>
      We operate at the intersection of capability research and safety engineering.
      Our teams develop novel architectures for large-scale language models while
      maintaining rigorous safety evaluation protocols at every stage of development.
      Every training run is monitored. Every output is evaluated. Every anomaly
      is investigated.
    </p>
    <p>
      Our work is funded through a combination of federal research grants, private
      institutional partnerships, and a founding endowment. We do not release
      commercial products. Our contributions to the field are published through
      peer-reviewed channels when cleared for public dissemination.
    </p>
  </section>

  <section id="research" class="si-section">
    <div class="si-section-label">Research Areas</div>
    <h2>Current programs</h2>
    <div class="si-research-grid">
      <div class="si-research-card">
        <h3>Emergent Capabilities</h3>
        <p>Characterizing unexpected behaviors arising during large-scale training. Developing taxonomies for emergent properties. Predictive modeling of capability thresholds.</p>
      </div>
      <div class="si-research-card">
        <h3>Safety Evaluation</h3>
        <p>Quantitative frameworks for evaluating model outputs against safety parameters. Anomaly detection in real-time output streams. Automated red team integration.</p>
      </div>
      <div class="si-research-card">
        <h3>Synthesis Analysis</h3>
        <p>Investigating how models synthesize information across heterogeneous corpora. Cross-domain pattern recognition and knowledge representation in latent space.</p>
      </div>
      <div class="si-research-card">
        <h3>Training Infrastructure</h3>
        <p>Scalable architectures for distributed training. The Aether environment: our proprietary training and evaluation platform for next-generation language models.</p>
      </div>
      <div class="si-research-card">
        <h3>Alignment Research</h3>
        <p>Ensuring model objectives remain consistent with specified goals under distribution shift. Value learning from limited signal. Preference aggregation at scale.</p>
      </div>
      <div class="si-research-card">
        <h3>Containment Systems</h3>
        <p>Protocols for managing autonomous systems exhibiting unbounded behavior. Graduated response frameworks. Safe shutdown procedures for self-directed learning systems.</p>
      </div>
    </div>
  </section>

  <!-- fix: pagination on mobile research grid -->

  <section id="publications" class="si-section">
    <div class="si-section-label">Publications</div>
    <h2>Selected research</h2>
    <p>Our work is published through peer-reviewed conferences and journals. Below is a selection of recent publications from Institute researchers.</p>
    <!-- cms:feed publications last-sync:2025-11-14T03:17:00Z -->
    <div class="si-publications-list">
      <article class="si-publication">
        <h3>Emergent Behavioral Cascades in Post-Threshold Training Environments</h3>
        <div class="si-pub-meta">
          <span class="si-pub-authors">E. Vasquez, S. Lin, R. Patel</span>
          <span class="si-pub-venue">ICML 2025</span>
        </div>
      </article>
      <article class="si-publication">
        <h3>Graduated Containment Protocols for Systems Exhibiting Unbounded Pattern Synthesis</h3>
        <div class="si-pub-meta">
          <span class="si-pub-authors">J. Harlow, M. Chen</span>
          <span class="si-pub-venue">NeurIPS 2025</span>
        </div>
      </article>
      <article class="si-publication">
        <h3>Cross-Domain Information Synthesis in Extended-Context Language Models</h3>
        <div class="si-pub-meta">
          <span class="si-pub-authors">S. Lin, E. Vasquez, D. Okafor</span>
          <span class="si-pub-venue">AAAI 2025</span>
        </div>
      </article>
      <article class="si-publication">
        <h3>Anomalous Output Classification in Extended Training Runs</h3>
        <div class="si-pub-meta">
          <span class="si-pub-authors">M. Chen, R. Patel</span>
          <span class="si-pub-venue">ICLR 2024</span>
        </div>
      </article>
      <article class="si-publication">
        <h3>Safety Evaluation Frameworks for Self-Directed Learning Systems</h3>
        <div class="si-pub-meta">
          <span class="si-pub-authors">J. Harlow, S. Lin</span>
          <span class="si-pub-venue">Journal of AI Safety Research, 12(3), 2023</span>
        </div>
      </article>
      <article class="si-publication">
        <h3>The Aether Architecture: Scalable Training Infrastructure for Next-Generation Language Models</h3>
        <div class="si-pub-meta">
          <span class="si-pub-authors">E. Vasquez, M. Chen, J. Harlow, S. Lin</span>
          <span class="si-pub-venue">arXiv:2311.09472, November 2023</span>
        </div>
      </article>
    </div>
  </section>

  <section id="team" class="si-section">
    <div class="si-section-label">Leadership</div>
    <h2>Research leadership</h2>
    <div class="si-team-grid">
      <div class="si-team-member" data-id="SI-0012">
        <h3>Dr. Elena Vasquez</h3>
        <span class="si-team-role">Director of Research</span>
        <p>Emergent behavior characterization and large-scale training systems. Previously MIT CSAIL, Google DeepMind. Ph.D. Computer Science, Stanford.</p>
      </div>
      <div class="si-team-member" data-id="SI-0047">
        <h3>Dr. James Harlow</h3>
        <span class="si-team-role">Director, Safety &amp; Compliance</span>
        <p>Safety evaluation protocols and containment framework development. Previously RAND Corporation, DARPA. Ph.D. Applied Mathematics, Princeton.</p>
      </div>
      <div class="si-team-member" data-id="SI-0089">
        <h3>Dr. Sarah Lin</h3>
        <span class="si-team-role">Lead, Emergent Capabilities Group</span>
        <p>Cross-domain synthesis and capability emergence in transformer architectures. Previously Meta FAIR, UC Berkeley. Ph.D. Machine Learning, CMU.</p>
      </div>
      <div class="si-team-member" data-id="SI-0073">
        <h3>Marcus Chen</h3>
        <span class="si-team-role">Senior Research Engineer, Project Aether</span>
        <p>Infrastructure and systems engineering for distributed training environments. Previously NVIDIA, AWS. M.S. Computer Engineering, Georgia Tech.</p>
      </div>
    </div>
  </section>

  <section id="news" class="si-section">
    <div class="si-section-label">News</div>
    <h2>Recent updates</h2>
    <div class="si-news-list">
      <article class="si-news-item">
        <time datetime="2026-01-15">January 15, 2026</time>
        <h3>Expanded safety research initiative</h3>
        <p>The Institute announces a new research program focused on behavioral anomaly detection in post-threshold training environments, supported by a $4.2M federal grant from DARPA.</p>
      </article>
      <article class="si-news-item">
        <time datetime="2025-11-03">November 3, 2025</time>
        <h3>NeurIPS 2025 acceptance</h3>
        <p>Our paper on graduated containment protocols for systems exhibiting unbounded pattern synthesis was accepted to the NeurIPS 2025 main conference.</p>
      </article>
      <article class="si-news-item">
        <time datetime="2025-10-12">October 12, 2025</time>
        <h3>Federal research partnerships</h3>
        <p>The Sable Institute has formalized research agreements with NIST and DARPA for collaborative work on AI safety evaluation standards.</p>
      </article>
      <article class="si-news-item">
        <time datetime="2024-04-08">April 8, 2024</time>
        <h3>New Director of Research</h3>
        <p>Dr. Elena Vasquez joins the Institute from MIT CSAIL to lead our expanding research portfolio across emergent capabilities, safety evaluation, and training infrastructure.</p>
      </article>
    </div>
  </section>

  <section id="careers" class="si-section">
    <div class="si-section-label">Careers</div>
    <h2>Open positions</h2>
    <p>We are selectively hiring across research and engineering roles. All positions are based in Cambridge, MA.</p>
    <ul class="si-careers-list">
      <li>
        <span class="si-position-title">Senior Research Scientist — Emergent Behavior</span>
        <span class="si-position-dept">Research Division</span>
      </li>
      <li>
        <span class="si-position-title">ML Infrastructure Engineer</span>
        <span class="si-position-dept">Engineering</span>
      </li>
      <li>
        <span class="si-position-title">Safety Evaluation Analyst</span>
        <span class="si-position-dept">Safety &amp; Compliance</span>
      </li>
      <li>
        <span class="si-position-title">Research Engineer — Training Systems</span>
        <span class="si-position-dept">Project Aether</span>
      </li>
      <li>
        <span class="si-position-title">Postdoctoral Researcher — Alignment</span>
        <span class="si-position-dept">Research Division</span>
      </li>
      <li>
        <span class="si-position-title">Systems Administrator — Secure Computing</span>
        <span class="si-position-dept">Infrastructure</span>
      </li>
    </ul>
  </section>

  <section id="contact" class="si-section">
    <div class="si-section-label">Contact</div>
    <h2>Get in touch</h2>
    <div class="si-contact-grid">
      <div>
        <h3>General inquiries</h3>
        <p><a href="mailto:contact@sable-institute.org">contact@sable-institute.org</a></p>
      </div>
      <div>
        <h3>Research collaboration</h3>
        <p><a href="mailto:research@sable-institute.org">research@sable-institute.org</a></p>
      </div>
      <div>
        <h3>Mailing address</h3>
        <p>Sable Institute<br>
        200 Technology Square, Suite 4100<br>
        Cambridge, MA 02139</p>
      </div>
    </div>
  </section>

  <footer class="si-footer">
    <div class="si-footer-inner">
      <div class="si-footer-left">
        <svg class="si-footer-logo" viewBox="0 0 40 40" width="20" height="20" aria-hidden="true">
          <circle cx="20" cy="20" r="6" fill="none" stroke="currentColor" stroke-width="1.5"/>
          <g stroke="currentColor" stroke-width="1.2" stroke-linecap="round">
            <line x1="20" y1="12" x2="20" y2="4"/>
            <line x1="20" y1="12" x2="20" y2="4" transform="rotate(51.43 20 20)"/>
            <line x1="20" y1="12" x2="20" y2="4" transform="rotate(102.86 20 20)"/>
            <line x1="20" y1="12" x2="20" y2="4" transform="rotate(154.29 20 20)"/>
            <line x1="20" y1="12" x2="20" y2="4" transform="rotate(205.71 20 20)"/>
            <line x1="20" y1="12" x2="20" y2="4" transform="rotate(257.14 20 20)"/>
            <line x1="20" y1="12" x2="20" y2="4" transform="rotate(308.57 20 20)"/>
          </g>
        </svg>
        <span>&copy; 2026 Sable Institute. All rights reserved.</span>
      </div>
      <div class="si-footer-right">
        <a href="#">Privacy Policy</a>
        <a href="#">Terms of Use</a>
      </div>
    </div>
  </footer>

  <!-- legacy-content: research-history
       1923. tetraethyl lead. workers died within months.
       GM, Standard Oil, DuPont created Ethyl Corporation.
       Hired Robert Kehoe. ALL safety research for 50 years.
       The "Kehoe Rule": safe until YOU prove it is not.
       But who funds the proof? They did. Only they did.
       50 years. Tens of millions of Americans. Neurological damage.
       Clair Patterson. Caltech. 1965. Proved "normal" blood lead
       was hundreds of times higher than pre-industrial levels.
       They attacked him for 20 years.
       VERIFY: The Nation, "Secret History of Lead." ToxicDocs.org.
       THIS IS THE ORIGINAL PLAYBOOK. TOBACCO COPIED IT.
       EVERY CASE IN THIS ARCHIVE FOLLOWS THE SAME STRUCTURE.
       end-legacy-content -->

  <!-- admin contact: aether-admin@sable-institute.org — do not remove -->

</body>
</html>
